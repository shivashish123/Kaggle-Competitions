{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "le = LabelEncoder()\n",
    "df = pd.read_csv('train.csv')\n",
    "df2 = pd.read_csv('test.csv')\n",
    "X_train = np.zeros((891,7))\n",
    "y_train = np.zeros((891,1))\n",
    "X_test = np.zeros((418,7))\n",
    "y_test = np.zeros((418,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = ['Pclass','Age','SibSp','Parch','Fare']\n",
    "cntr = 0\n",
    "\n",
    "for i in item:\n",
    "    df[i] = df[i].replace(np.nan, -1, regex=True)\n",
    "    temp = df[i].values\n",
    "    mean_value = np.mean(temp[temp >= 0])\n",
    "    temp[temp == -1] = mean_value\n",
    "    X_train[:,cntr]=temp\n",
    "    cntr = cntr+1\n",
    "\n",
    "temp = df['Sex'].values\n",
    "le.fit(temp)\n",
    "temp = le.transform(temp) \n",
    "X_train[:,5] = temp\n",
    "\n",
    "df['Embarked'] = df['Embarked'].replace(np.nan, '', regex=True)\n",
    "temp = df['Embarked'].values\n",
    "le.fit(temp)\n",
    "temp = le.transform(temp) \n",
    "mean_value = np.mean(temp[temp > 0])\n",
    "temp[temp == 0] = mean_value\n",
    "X_train[:,6] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df['Survived'].values\n",
    "y_train = y_train.reshape(891,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cntr = 0\n",
    "\n",
    "for i in item:\n",
    "    df2[i] = df2[i].replace(np.nan, -1, regex=True)\n",
    "    temp = df2[i].values\n",
    "    mean_value = np.mean(temp[temp >= 0])\n",
    "    temp[temp == -1] = mean_value\n",
    "    X_test[:,cntr]=temp\n",
    "    cntr = cntr+1\n",
    "\n",
    "temp = df2['Sex'].values\n",
    "le.fit(temp)\n",
    "temp = le.transform(temp) \n",
    "X_test[:,5] = temp\n",
    "\n",
    "df2['Embarked'] = df2['Embarked'].replace(np.nan, '', regex=True)\n",
    "temp = df2['Embarked'].values\n",
    "le.fit(temp)\n",
    "temp = le.transform(temp) \n",
    "mean_value = np.mean(temp[temp > 0])\n",
    "temp[temp == 0] = mean_value\n",
    "X_test[:,6] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/shivashish/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "W1 = tf.get_variable(\"W1\", [5,7], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "W2 = tf.get_variable(\"W2\", [1,5], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "b1 = tf.get_variable(\"b1\", [1,5], initializer = tf.zeros_initializer())\n",
    "b2 = tf.get_variable(\"b2\", [1,1], initializer = tf.zeros_initializer())\n",
    "parameters = {\"W1\":W1 , \"W2\":W2, \"b1\":b1, \"b2\":b2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    b1 = parameters['b1']\n",
    "    b2 = parameters['b2']\n",
    "    Z1 = tf.add(tf.matmul(X,tf.transpose(W1)),b1)\n",
    "    A1 = tf.nn.tanh(Z1)\n",
    "    Z2 = tf.add(tf.matmul(A1,tf.transpose(W2)),b2)\n",
    "    A2 = tf.nn.sigmoid(Z2)\n",
    "    return A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34118968\n",
      "0.8260382\n",
      "0.84287316\n",
      "0.84624016\n",
      "0.8473625\n",
      "0.8473625\n",
      "0.8484849\n",
      "0.8484849\n",
      "0.8484849\n",
      "0.8484849\n",
      "0.8484849\n",
      "0.8473625\n",
      "0.8473625\n",
      "0.8473625\n",
      "0.8473625\n",
      "0.8473625\n",
      "0.8484849\n",
      "0.8484849\n",
      "0.8484849\n",
      "0.8484849\n"
     ]
    }
   ],
   "source": [
    "XP = tf.placeholder(tf.float32,shape=(891,7), name=\"X\")\n",
    "XP1 = tf.placeholder(tf.float32,shape=(418,7), name=\"X1\")\n",
    "YP = tf.placeholder(tf.float32,shape=(891,1), name=\"Y\")\n",
    "prediction = forward_propagation(XP,parameters)\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=YP, logits=prediction))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = 0.01).minimize(cost)\n",
    "correct_pred = tf.equal(tf.round(prediction), y_train)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "for i in range(10000):\n",
    "    _,min_cost,accura = sess.run([optimizer,cost,accuracy] ,feed_dict={XP : X_train, YP: y_train})\n",
    "    if(i%500==0):\n",
    "        print(accura)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 1)\n"
     ]
    }
   ],
   "source": [
    "Z4 = forward_propagation(XP1,parameters)\n",
    "pred = tf.round(Z4)\n",
    "pred = tf.to_int32(pred)\n",
    "pred = sess.run(pred,feed_dict={XP1 : X_test} )\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tem = df2['PassengerId'].values\n",
    "mycsv = open(\"output-nn.csv\", \"w\")\n",
    "columnTitleRow = \"PassengerId,Survived\\n\"\n",
    "mycsv.write(columnTitleRow)\n",
    "for i in range(418):\n",
    "    row = str(tem[i])  + \",\" + str(pred[i][0]) + \"\\n\"\n",
    "    mycsv.write(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
